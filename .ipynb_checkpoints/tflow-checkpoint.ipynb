{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "#from tensorflow.python.keras.applications.ResNet50 import preprocess_input\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir='./question_1_dataset/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_imgs=len(glob.glob(img_dir+'/*.png'))\n",
    "total_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames=['{}.png'.format(i) for i in range(1,total_imgs+1)]\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths=[join(img_dir,filename) for filename in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[load_img(img_path,target_size=(100,100)) for img_path in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array([img_to_array(img) for img in imgs])\n",
    "img_array=img_array/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4465, 100, 100, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(img_paths[4464]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x=img_array\n",
    "df=pd.read_csv('./question_1_dataset/train.csv')\n",
    "y_out=np.array(df['category'])\n",
    "y=to_categorical(y_out)\n",
    "y=y[:,1:]\n",
    "\n",
    "x_train,x_cv,y_train,y_cv=train_test_split(x,y,test_size=0.2,random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_with_aug = ImageDataGenerator( horizontal_flip = True,\n",
    "                                              width_shift_range = 0.1,\n",
    "                                              height_shift_range = 0.1,validation_split=0.2)\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(20,kernel_size=3,activation='relu',input_shape=(100,100,3)))\n",
    "model.add(Conv2D(20,kernel_size=3,activation='relu'))\n",
    "model.add(Conv2D(20,kernel_size=3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(16,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=100\n",
    "i=0\n",
    "#train_generator = data_generator_with_aug.flow_from_directory(\n",
    " #       './question_1_dataset/train/',target_size=(150,150),batch_size=32,class_mode='categorical'\n",
    "  #      )\n",
    "train_generator = data_generator_with_aug.flow(\n",
    "        x_train,y_train,batch_size=100\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 30 steps, validate on 893 samples\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 44s 1s/step - loss: 2.0808 - accuracy: 0.2799 - val_loss: 1.5074 - val_accuracy: 0.4535\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 45s 2s/step - loss: 1.5324 - accuracy: 0.4371 - val_loss: 1.3587 - val_accuracy: 0.4815\n",
      "Epoch 3/10\n",
      " 7/30 [======>.......................] - ETA: 33s - loss: 1.5086 - accuracy: 0.4371"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b62837c7b287>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         steps_per_epoch=30,validation_data=(x_cv,y_cv))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs = 10,\n",
    "        steps_per_epoch=30,validation_data=(x_cv,y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(x_cv)\n",
    "yhat=yhat.argmax(axis=1)\n",
    "#y_cv=y_cv.argmax(axis=1)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "#f1_score(y_cv, yhat, average='weighted')\n",
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3572 samples, validate on 893 samples\n",
      "Epoch 1/3\n",
      "3572/3572 [==============================] - 54s 15ms/sample - loss: 0.7637 - accuracy: 0.7256 - val_loss: 0.5822 - val_accuracy: 0.7839\n",
      "Epoch 2/3\n",
      "3572/3572 [==============================] - 58s 16ms/sample - loss: 0.2521 - accuracy: 0.9082 - val_loss: 0.5199 - val_accuracy: 0.8007\n",
      "Epoch 3/3\n",
      "3572/3572 [==============================] - 62s 17ms/sample - loss: 0.1342 - accuracy: 0.9532 - val_loss: 0.4969 - val_accuracy: 0.8287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df12199d48>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x,y,batch_size=50,epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425272091730246"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "yhat=model.predict(x)\n",
    "yhat=yhat.argmax(axis=1)+1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_out, yhat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_dir_test='./question_1_dataset/test/'\n",
    "total_imgs=len(glob.glob(img_dir_test+'/*.png'))\n",
    "fnames_test=['{}.png'.format(i) for i in range(1,total_imgs+1)]\n",
    "img_paths=[join(img_dir,filename) for filename in fnames]\n",
    "imgs=[load_img(img_path,target_size=(100,100)) for img_path in img_paths]\n",
    "img_array_test = np.array([img_to_array(img) for img in imgs])\n",
    "img_array_test=img_array/255\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_array_test=img_array\n",
    "import csv\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
