{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "#from tensorflow.python.keras.applications.ResNet50 import preprocess_input\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir='./question_1_dataset/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_imgs=len(glob.glob(img_dir+'/*.png'))\n",
    "total_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames=['{}.png'.format(i) for i in range(1,total_imgs+1)]\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths=[join(img_dir,filename) for filename in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[load_img(img_path,target_size=(100,100)) for img_path in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array([img_to_array(img) for img in imgs])\n",
    "img_array=img_array/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4465, 100, 100, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(img_paths[4464]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x=img_array\n",
    "df=pd.read_csv('./question_1_dataset/train.csv')\n",
    "y_out=np.array(df['category'])\n",
    "y=to_categorical(y_out)\n",
    "y=y[:,1:]\n",
    "\n",
    "x_train,x_cv,y_train,y_cv=train_test_split(x,y,test_size=0.2,random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_with_aug = ImageDataGenerator( horizontal_flip = True,\n",
    "                                              width_shift_range = 0.1,\n",
    "                                              height_shift_range = 0.1,validation_split=0.2)\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(20,kernel_size=3,activation='relu',input_shape=(100,100,3)))\n",
    "model.add(Conv2D(20,kernel_size=3,activation='relu'))\n",
    "model.add(Conv2D(20,kernel_size=3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(16,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=100\n",
    "i=0\n",
    "#train_generator = data_generator_with_aug.flow_from_directory(\n",
    " #       './question_1_dataset/train/',target_size=(150,150),batch_size=32,class_mode='categorical'\n",
    "  #      )\n",
    "train_generator = data_generator_with_aug.flow(\n",
    "        x_train,y_train,batch_size=100\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-b62837c7b287>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 30 steps, validate on 893 samples\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 61s 2s/step - loss: 2.1919 - accuracy: 0.2554 - val_loss: 1.6302 - val_accuracy: 0.3483\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 64s 2s/step - loss: 1.5605 - accuracy: 0.4159 - val_loss: 1.2825 - val_accuracy: 0.4826\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.3921 - accuracy: 0.4613 - val_loss: 1.2134 - val_accuracy: 0.5196\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 60s 2s/step - loss: 1.2815 - accuracy: 0.5101 - val_loss: 1.2396 - val_accuracy: 0.5274\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 65s 2s/step - loss: 1.1840 - accuracy: 0.5575 - val_loss: 1.2171 - val_accuracy: 0.5039\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 62s 2s/step - loss: 1.1340 - accuracy: 0.5585 - val_loss: 1.2490 - val_accuracy: 0.5297\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 66s 2s/step - loss: 1.1109 - accuracy: 0.5676 - val_loss: 1.0930 - val_accuracy: 0.6114\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.0488 - accuracy: 0.5821 - val_loss: 1.1625 - val_accuracy: 0.5588\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.0463 - accuracy: 0.6040 - val_loss: 1.2095 - val_accuracy: 0.5700\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.9874 - accuracy: 0.6107 - val_loss: 0.9447 - val_accuracy: 0.6585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d8a14a188>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs = 10,\n",
    "        steps_per_epoch=30,validation_data=(x_cv,y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(x_cv)\n",
    "yhat=yhat.argmax(axis=1)+1\n",
    "y_cv=y_cv.argmax(axis=1)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6361793174229131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_cv, yhat, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3572 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      "3572/3572 [==============================] - 74s 21ms/sample - loss: 0.5833 - accuracy: 0.7802 - val_loss: 0.5275 - val_accuracy: 0.7940\n",
      "Epoch 2/10\n",
      "3572/3572 [==============================] - 69s 19ms/sample - loss: 0.2265 - accuracy: 0.9132 - val_loss: 0.5491 - val_accuracy: 0.8175\n",
      "Epoch 3/10\n",
      "3572/3572 [==============================] - 64s 18ms/sample - loss: 0.1390 - accuracy: 0.9426 - val_loss: 0.5921 - val_accuracy: 0.8108\n",
      "Epoch 4/10\n",
      "3572/3572 [==============================] - 63s 18ms/sample - loss: 0.0896 - accuracy: 0.9647 - val_loss: 0.6058 - val_accuracy: 0.8029\n",
      "Epoch 5/10\n",
      "3572/3572 [==============================] - 81s 23ms/sample - loss: 0.0579 - accuracy: 0.9748 - val_loss: 0.5090 - val_accuracy: 0.8387\n",
      "Epoch 6/10\n",
      "3572/3572 [==============================] - 78s 22ms/sample - loss: 0.0501 - accuracy: 0.9798 - val_loss: 0.5408 - val_accuracy: 0.8264\n",
      "Epoch 7/10\n",
      "3572/3572 [==============================] - 77s 22ms/sample - loss: 0.0255 - accuracy: 0.9891 - val_loss: 0.6620 - val_accuracy: 0.8108\n",
      "Epoch 8/10\n",
      "3572/3572 [==============================] - 78s 22ms/sample - loss: 0.0222 - accuracy: 0.9913 - val_loss: 0.6737 - val_accuracy: 0.8208\n",
      "Epoch 9/10\n",
      "3572/3572 [==============================] - 76s 21ms/sample - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.6433 - val_accuracy: 0.8208\n",
      "Epoch 10/10\n",
      "3572/3572 [==============================] - 79s 22ms/sample - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.7038 - val_accuracy: 0.8231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d985a4ac8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x,y,batch_size=50,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9636753030440856"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "yhat=model.predict(x)\n",
    "yhat=yhat.argmax(axis=1)+1\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_out, yhat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_dir_test='./question_1_dataset/test/'\n",
    "total_imgs_test=len(glob.glob(img_dir_test+'/*.png'))\n",
    "fnames_test=['{}.png'.format(i) for i in range(total_imgs+1,total_imgs+total_imgs_test+1)]\n",
    "img_paths_test=[join(img_dir_test,filename) for filename in fnames_test]\n",
    "imgs_test=[load_img(img_path_test,target_size=(100,100)) for img_path_test in img_paths_test]\n",
    "img_array_test = np.array([img_to_array(img) for img in imgs_test])\n",
    "img_array_test=img_array_test/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=img_array_test\n",
    "yhat_test=model.predict(x_test)\n",
    "yhat_test=yhat_test.argmax(axis=1)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6379,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final=np.hstack([yhat,yhat_test])\n",
    "y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./question_1_dataset/Testfinal.csv\",\"w\") as file:\n",
    "    writer=csv.writer(file)\n",
    "    for i in range(total_imgs):\n",
    "        writer.writerow([fnames[i],yhat[i]])\n",
    "    for i in range(total_imgs_test):\n",
    "        writer.writerow([fnames_test[i],yhat_test[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./question_1_dataset/Testfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.png</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.png</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>6375.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>6376.png</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>6377.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>6378.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>6379.png</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1.png   9\n",
       "0        2.png   3\n",
       "1        3.png   9\n",
       "2        4.png   8\n",
       "3        5.png  13\n",
       "4        6.png   7\n",
       "...        ...  ..\n",
       "6373  6375.png   8\n",
       "6374  6376.png  13\n",
       "6375  6377.png   7\n",
       "6376  6378.png   3\n",
       "6377  6379.png  10\n",
       "\n",
       "[6378 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'my change'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "'my change'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'another change'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "'another change'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}